{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7432092,"sourceType":"datasetVersion","datasetId":4324996}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TP INF4248 - Classification d'images de d√©chets avec CNN\n\n# Entra√Ænement d'un CNN avec Keras\nBas√© sur le dataset realwaste :  \n\n**Membres du groupe** :  \n1. FETUE FOKO NATHANAEL - 21T2382  \n2. DJONTHU DJONTHU MAURICE JUNIOR - 21T2557  \n3. Essouma Mbarga Valerie constance - 18T2880  \n\n# üóëÔ∏è Entra√Ænement d'un CNN sur RealWaste avec Keras  \n**Objectif** : Classifier des images de d√©chets authentiques dans un environnement de d√©charge avec un r√©seau de neurones convolutif  \n\n**Dataset** : RealWaste  \n- 9 classes (types de mat√©riaux : Cardboard, Food Organics, Glass, Metal, Miscellaneous Trash, Paper, Plastic, Textile Trash, Vegetation)  \n- 4 752 images au total (524x524 pixels en couleur), captur√©es dans une d√©charge  \n- Distribution in√©gale : de 318 (Textile Trash) √† 921 (Plastic) images par classe  \n\n**Approche** :  \n1. Architecture CNN personnalis√©e (plusieurs couches convolutives avec dropout)  \n2. Entra√Ænement from scratch avec augmentation de donn√©es  \n3. √âvaluation des performances sur un ensemble de test  ","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport random\nfrom pathlib import Path\n\n# Chemins (√† ajuster selon o√π tu d√©compresses RealWaste sur Kaggle ou localement)\ndata_dir = Path(\"/kaggle/input/realwaste/realwaste-main/RealWaste\")  # Suppose que tu importes le dataset dans Kaggle\ndataset_dir = Path(\"/kaggle/working/realwaste\")\ntrain_dir = dataset_dir / \"train\"\ntest_dir = dataset_dir / \"test\"\n\ntrain_dir.mkdir(parents=True, exist_ok=True)\ntest_dir.mkdir(parents=True, exist_ok=True)\n\n# Liste des classes de RealWaste\nclass_names = [\"cardboard\", \"food_organics\", \"glass\", \"metal\", \"miscellaneous_trash\", \n               \"paper\", \"plastic\", \"textile_trash\", \"vegetation\"]\n\n# Parcourir les classes et diviser en train/test (80/20)\nfor class_name in class_names:\n    class_dir = data_dir / class_name\n    if class_dir.is_dir():\n        images = list(class_dir.glob(\"*.jpg\"))  # ou autre extension selon le dataset\n        random.shuffle(images)\n        split_idx = int(0.8 * len(images))\n        train_images, test_images = images[:split_idx], images[split_idx:]\n        \n        (train_dir / class_name).mkdir(parents=True, exist_ok=True)\n        (test_dir / class_name).mkdir(parents=True, exist_ok=True)\n        \n        for img in train_images:\n            shutil.copy(img, train_dir / class_name / img.name)\n        for img in test_images:\n            shutil.copy(img, test_dir / class_name / img.name)\n\nprint(\"Dataset RealWaste structur√© avec succ√®s !!!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:36:19.246604Z","iopub.execute_input":"2025-04-03T18:36:19.246901Z","iopub.status.idle":"2025-04-03T18:36:19.272993Z","shell.execute_reply.started":"2025-04-03T18:36:19.246881Z","shell.execute_reply":"2025-04-03T18:36:19.272287Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Dataset RealWaste structur√© avec succ√®s !!!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from pathlib import Path\n\ndownload_dir = Path('/kaggle/working')\nprint(\"a\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T17:56:00.812920Z","iopub.execute_input":"2025-04-03T17:56:00.813207Z","iopub.status.idle":"2025-04-03T17:56:00.817670Z","shell.execute_reply.started":"2025-04-03T17:56:00.813185Z","shell.execute_reply":"2025-04-03T17:56:00.816822Z"}},"outputs":[{"name":"stdout","text":"a\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Image augmentations\nexample_generator = ImageDataGenerator(\n    rescale=1 / 255.,           # normalize pixel values between 0-1\n    vertical_flip=True,         # vertical transposition\n    horizontal_flip=True,       # horizontal transposition\n    rotation_range=90,          # random rotation at 90 degrees\n    height_shift_range=0.3,     # shift the height of the image 30%\n    brightness_range=[0.1, 0.9] # specify the range in which to decrease/increase brightness\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# G√©n√©rateur d'entra√Ænement avec augmentations\ntrain_datagen = ImageDataGenerator(\n    rescale=1/255.,\n    brightness_range=[0.1, 0.7],\n    width_shift_range=0.5,\n    rotation_range=90,\n    horizontal_flip=True,\n    vertical_flip=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T17:56:51.161942Z","iopub.execute_input":"2025-04-03T17:56:51.162250Z","iopub.status.idle":"2025-04-03T17:57:02.676359Z","shell.execute_reply.started":"2025-04-03T17:56:51.162225Z","shell.execute_reply":"2025-04-03T17:57:02.675551Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\n\nclass_subset = sorted(os.listdir('/kaggle/input/realwate/images'))[:10]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BATCH_SIZE = 32\ntraingen = train_datagen.flow_from_directory(\n    directory=str(train_dir),\n    target_size=(524, 524),  # Taille native de RealWaste\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    classes=class_subset,\n    subset = 'training',\n    shuffle=True,\n    seed=42\n)\n\n\nvalidgen = valid_datagen.flow_from_directory(\n    directory=str(test_dir),\n    target_size=(524, 524),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    #classes=class_names,\n    classes=class_subset\n    subset = 'validation',\n    shuffle=True,\n    seed=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T18:00:28.553258Z","iopub.execute_input":"2025-04-03T18:00:28.553555Z","iopub.status.idle":"2025-04-03T18:00:28.566337Z","shell.execute_reply.started":"2025-04-03T18:00:28.553533Z","shell.execute_reply":"2025-04-03T18:00:28.565716Z"}},"outputs":[{"name":"stdout","text":"Found 0 images belonging to 9 classes.\nFound 0 images belonging to 9 classes.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\nfrom keras.regularizers import l1_l2\n\nmodel = Sequential()\n\n#### Input Layer ####\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',\n                 activation='relu', input_shape=(128, 128, 3)))\n\n#### Convolutional Layers ####\nmodel.add(Conv2D(32, (3,3), activation='relu'))\nmodel.add(MaxPooling2D((2,2)))  # Pooling\nmodel.add(Dropout(0.2)) # Dropout\n\nmodel.add(Conv2D(64, (3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(64, (3,3), activation='relu'))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, (3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(128, (3,3), activation='relu'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D((2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(512, (5,5), padding='same', activation='relu'))\nmodel.add(Conv2D(512, (5,5), activation='relu'))\nmodel.add(MaxPooling2D((4,4)))\nmodel.add(Dropout(0.2))\n\n#### Fully-Connected Layer ####\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(len(class_subset), activation='softmax'))\n\nmodel.summary() # a handy way to inspect the architecture","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n\nfrom keras.optimizers import RMSprop\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nimport matplotlib.pyplot as plt\n\n# V√©rification des g√©n√©rateurs (ajout√© pour diagnostic)\nprint(\"Nombre d'√©chantillons dans traingen :\", traingen.samples)\nprint(\"Nombre d'√©chantillons dans validgen :\", validgen.samples)\nprint(\"Taille du batch (BATCH_SIZE) :\", BATCH_SIZE)\n\nsteps_per_epoch = traingen.samples // BATCH_SIZE\nval_steps = validgen.samples // BATCH_SIZE\n\n# Assure au moins 1 step si le nombre d'√©chantillons est faible\nsteps_per_epoch = max(1, steps_per_epoch)\nval_steps = max(1, val_steps)\n\nprint(\"Steps per epoch :\", steps_per_epoch)\nprint(\"Validation steps :\", val_steps)\n\nn_epochs = 100\n\noptimizer = RMSprop(learning_rate=0.0001)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n\n# Sauvegarde des poids au format .weights.h5 (conforme aux versions r√©centes)\ncheckpointer = ModelCheckpoint(filepath='img_model.weights.best.weights.h5', \n                               verbose=1, \n                               save_best_only=True,\n                               save_weights_only=True)\n\n# Arr√™t anticip√©\nearly_stop = EarlyStopping(monitor='val_loss',\n                           patience=10,\n                           restore_best_weights=True,\n                           mode='min')\n\n# Entra√Ænement du mod√®le\nhistory = model.fit(traingen,\n                    epochs=n_epochs, \n                    steps_per_epoch=steps_per_epoch,\n                    validation_data=validgen,\n                    validation_steps=val_steps,\n                    callbacks=[early_stop, checkpointer],\n                    verbose=1)  # verbose=1 pour voir la progression\n\n# Visualisation avec matplotlib\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Loss over Epochs')\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_generator = ImageDataGenerator(rescale=1/255.)\n\ntestgen = test_generator.flow_from_directory(download_dir/'realwaste/test',\n                                             target_size=(128, 128),\n                                             batch_size=1,\n                                             class_mode=None,\n                                             classes=class_subset, \n                                             shuffle=False,\n                                             seed=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\n# Charger les poids (assure-toi que le fichier existe)\nmodel.load_weights('img_model.weights.best.weights.h5')\n\n# Faire les pr√©dictions (probabilit√©s pour chaque classe)\npredictions = model.predict(testgen)\n\n# Extraire les classes pr√©dites en prenant l'indice de la probabilit√© maximale\npredicted_classes = np.argmax(predictions, axis=1)\n\n# R√©cup√©rer les indices et noms des classes\nclass_indices = traingen.class_indices\nclass_indices = dict((v, k) for k, v in class_indices.items())\ntrue_classes = testgen.classes\n\n# Afficher quelques exemples pour v√©rification\nprint(\"Classes pr√©dites (5 premi√®res) :\", [class_indices[i] for i in predicted_classes[:5]])\nprint(\"Classes r√©elles (5 premi√®res) :\", [class_indices[i] for i in true_classes[:5]])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import precision_recall_fscore_support, accuracy_score\n\ndef display_results(y_true, y_preds, class_labels):\n    \n    results = pd.DataFrame(precision_recall_fscore_support(y_true, y_preds),\n                          columns=class_labels).T\n\n    results.rename(columns={0: 'Precision', 1: 'Recall',\n                            2: 'F-Score', 3: 'Support'}, inplace=True)\n    \n    results.sort_values(by='F-Score', ascending=False, inplace=True)                           \n    global_acc = accuracy_score(y_true, y_preds)\n    \n    print(\"Overall Categorical Accuracy: {:.2f}%\".format(global_acc*100))\n    return results\n\ndef plot_predictions(y_true, y_preds, test_generator, class_indices):\n\n    fig = plt.figure(figsize=(20, 10))\n    for i, idx in enumerate(np.random.choice(test_generator.samples, size=20, replace=False)):\n        ax = fig.add_subplot(4, 5, i + 1, xticks=[], yticks=[])\n        ax.imshow(np.squeeze(test_generator[idx]))\n        pred_idx = y_preds[idx]\n        true_idx = y_true[idx]\n                \n        plt.tight_layout()\n        ax.set_title(\"{}\\n({})\".format(class_indices[pred_idx], class_indices[true_idx]),\n                     color=(\"green\" if pred_idx == true_idx else \"red\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_predictions(true_classes, predicted_classes, testgen, class_indices)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display_results(true_classes, predicted_classes, class_indices.values())","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}